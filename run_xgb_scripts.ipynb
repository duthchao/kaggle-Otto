{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.980793\n",
      "[1]\ttrain-mlogloss:1.817169\n",
      "[2]\ttrain-mlogloss:1.669235\n",
      "[3]\ttrain-mlogloss:1.549015\n",
      "[4]\ttrain-mlogloss:1.445978\n",
      "[5]\ttrain-mlogloss:1.357949\n",
      "[6]\ttrain-mlogloss:1.284582\n",
      "[7]\ttrain-mlogloss:1.216188\n",
      "[8]\ttrain-mlogloss:1.151986\n",
      "[9]\ttrain-mlogloss:1.093660\n",
      "[10]\ttrain-mlogloss:1.040376\n",
      "[11]\ttrain-mlogloss:0.991099\n",
      "[12]\ttrain-mlogloss:0.947887\n",
      "[13]\ttrain-mlogloss:0.907467\n",
      "[14]\ttrain-mlogloss:0.869320\n",
      "[15]\ttrain-mlogloss:0.835869\n",
      "[16]\ttrain-mlogloss:0.804082\n",
      "[17]\ttrain-mlogloss:0.773739\n",
      "[18]\ttrain-mlogloss:0.748522\n",
      "[19]\ttrain-mlogloss:0.721629\n",
      "[20]\ttrain-mlogloss:0.697873\n",
      "[21]\ttrain-mlogloss:0.676393\n",
      "[22]\ttrain-mlogloss:0.655483\n",
      "[23]\ttrain-mlogloss:0.635832\n",
      "[24]\ttrain-mlogloss:0.616998\n",
      "[25]\ttrain-mlogloss:0.599815\n",
      "[26]\ttrain-mlogloss:0.582867\n",
      "[27]\ttrain-mlogloss:0.568260\n",
      "[28]\ttrain-mlogloss:0.553007\n",
      "[29]\ttrain-mlogloss:0.539559\n",
      "[30]\ttrain-mlogloss:0.526234\n",
      "[31]\ttrain-mlogloss:0.514497\n",
      "[32]\ttrain-mlogloss:0.502715\n",
      "[33]\ttrain-mlogloss:0.491708\n",
      "[34]\ttrain-mlogloss:0.482127\n",
      "[35]\ttrain-mlogloss:0.471410\n",
      "[36]\ttrain-mlogloss:0.461975\n",
      "[37]\ttrain-mlogloss:0.452912\n",
      "[38]\ttrain-mlogloss:0.445147\n",
      "[39]\ttrain-mlogloss:0.436827\n",
      "[40]\ttrain-mlogloss:0.428837\n",
      "[41]\ttrain-mlogloss:0.421732\n",
      "[42]\ttrain-mlogloss:0.414332\n",
      "[43]\ttrain-mlogloss:0.407784\n",
      "[44]\ttrain-mlogloss:0.402174\n",
      "[45]\ttrain-mlogloss:0.396380\n",
      "[46]\ttrain-mlogloss:0.390757\n",
      "[47]\ttrain-mlogloss:0.385789\n",
      "[48]\ttrain-mlogloss:0.379527\n",
      "[49]\ttrain-mlogloss:0.374456\n",
      "[50]\ttrain-mlogloss:0.369814\n",
      "[51]\ttrain-mlogloss:0.364630\n",
      "[52]\ttrain-mlogloss:0.360149\n",
      "[53]\ttrain-mlogloss:0.355595\n",
      "[54]\ttrain-mlogloss:0.350985\n",
      "[55]\ttrain-mlogloss:0.347452\n",
      "[56]\ttrain-mlogloss:0.343391\n",
      "[57]\ttrain-mlogloss:0.339178\n",
      "[58]\ttrain-mlogloss:0.335700\n",
      "[59]\ttrain-mlogloss:0.332587\n",
      "[60]\ttrain-mlogloss:0.329109\n",
      "[61]\ttrain-mlogloss:0.325905\n",
      "[62]\ttrain-mlogloss:0.322724\n",
      "[63]\ttrain-mlogloss:0.319849\n",
      "[64]\ttrain-mlogloss:0.317121\n",
      "[65]\ttrain-mlogloss:0.314407\n",
      "[66]\ttrain-mlogloss:0.311729\n",
      "[67]\ttrain-mlogloss:0.308909\n",
      "[68]\ttrain-mlogloss:0.306149\n",
      "[69]\ttrain-mlogloss:0.303651\n",
      "[70]\ttrain-mlogloss:0.301040\n",
      "[71]\ttrain-mlogloss:0.298931\n",
      "[72]\ttrain-mlogloss:0.296602\n",
      "[73]\ttrain-mlogloss:0.294071\n",
      "[74]\ttrain-mlogloss:0.291529\n",
      "[75]\ttrain-mlogloss:0.289340\n",
      "[76]\ttrain-mlogloss:0.287237\n",
      "[77]\ttrain-mlogloss:0.285369\n",
      "[78]\ttrain-mlogloss:0.283440\n",
      "[79]\ttrain-mlogloss:0.281736\n",
      "[80]\ttrain-mlogloss:0.279709\n",
      "[81]\ttrain-mlogloss:0.277790\n",
      "[82]\ttrain-mlogloss:0.276084\n",
      "[83]\ttrain-mlogloss:0.274425\n",
      "[84]\ttrain-mlogloss:0.272564\n",
      "[85]\ttrain-mlogloss:0.271110\n",
      "[86]\ttrain-mlogloss:0.269939\n",
      "[87]\ttrain-mlogloss:0.268267\n",
      "[88]\ttrain-mlogloss:0.266732\n",
      "[89]\ttrain-mlogloss:0.265230\n",
      "[90]\ttrain-mlogloss:0.263858\n",
      "[91]\ttrain-mlogloss:0.262162\n",
      "[92]\ttrain-mlogloss:0.260682\n",
      "[93]\ttrain-mlogloss:0.258797\n",
      "[94]\ttrain-mlogloss:0.257538\n",
      "[95]\ttrain-mlogloss:0.256197\n",
      "[96]\ttrain-mlogloss:0.254803\n",
      "[97]\ttrain-mlogloss:0.253344\n",
      "[98]\ttrain-mlogloss:0.251741\n",
      "[99]\ttrain-mlogloss:0.250483\n",
      "[100]\ttrain-mlogloss:0.249149\n",
      "[101]\ttrain-mlogloss:0.247618\n",
      "[102]\ttrain-mlogloss:0.246206\n",
      "[103]\ttrain-mlogloss:0.245054\n",
      "[104]\ttrain-mlogloss:0.243963\n",
      "[105]\ttrain-mlogloss:0.243027\n",
      "[106]\ttrain-mlogloss:0.241662\n",
      "[107]\ttrain-mlogloss:0.240858\n",
      "[108]\ttrain-mlogloss:0.239523\n",
      "[109]\ttrain-mlogloss:0.238152\n",
      "[110]\ttrain-mlogloss:0.237024\n",
      "[111]\ttrain-mlogloss:0.235868\n",
      "[112]\ttrain-mlogloss:0.234768\n",
      "[113]\ttrain-mlogloss:0.233952\n",
      "[114]\ttrain-mlogloss:0.232860\n",
      "[115]\ttrain-mlogloss:0.231878\n",
      "[116]\ttrain-mlogloss:0.230810\n",
      "[117]\ttrain-mlogloss:0.229804\n",
      "[118]\ttrain-mlogloss:0.228800\n",
      "[119]\ttrain-mlogloss:0.227750\n",
      "[120]\ttrain-mlogloss:0.226690\n",
      "[121]\ttrain-mlogloss:0.225531\n",
      "[122]\ttrain-mlogloss:0.224657\n",
      "[123]\ttrain-mlogloss:0.223456\n",
      "[124]\ttrain-mlogloss:0.222410\n",
      "[125]\ttrain-mlogloss:0.221327\n",
      "[126]\ttrain-mlogloss:0.220287\n",
      "[127]\ttrain-mlogloss:0.219122\n",
      "[128]\ttrain-mlogloss:0.218051\n",
      "[129]\ttrain-mlogloss:0.217284\n",
      "[130]\ttrain-mlogloss:0.216290\n",
      "[131]\ttrain-mlogloss:0.215169\n",
      "[132]\ttrain-mlogloss:0.213892\n",
      "[133]\ttrain-mlogloss:0.212725\n",
      "[134]\ttrain-mlogloss:0.211929\n",
      "[135]\ttrain-mlogloss:0.210882\n",
      "[136]\ttrain-mlogloss:0.210103\n",
      "[137]\ttrain-mlogloss:0.208907\n",
      "[138]\ttrain-mlogloss:0.207993\n",
      "[139]\ttrain-mlogloss:0.206848\n",
      "[140]\ttrain-mlogloss:0.206009\n",
      "[141]\ttrain-mlogloss:0.204998\n",
      "[142]\ttrain-mlogloss:0.203682\n",
      "[143]\ttrain-mlogloss:0.202830\n",
      "[144]\ttrain-mlogloss:0.201805\n",
      "[145]\ttrain-mlogloss:0.200757\n",
      "[146]\ttrain-mlogloss:0.200031\n",
      "[147]\ttrain-mlogloss:0.199173\n",
      "[148]\ttrain-mlogloss:0.198264\n",
      "[149]\ttrain-mlogloss:0.197425\n",
      "[150]\ttrain-mlogloss:0.196721\n",
      "[151]\ttrain-mlogloss:0.196049\n",
      "[152]\ttrain-mlogloss:0.195215\n",
      "[153]\ttrain-mlogloss:0.194544\n",
      "[154]\ttrain-mlogloss:0.193460\n",
      "[155]\ttrain-mlogloss:0.192867\n",
      "[156]\ttrain-mlogloss:0.191982\n",
      "[157]\ttrain-mlogloss:0.191475\n",
      "[158]\ttrain-mlogloss:0.190667\n",
      "[159]\ttrain-mlogloss:0.189950\n",
      "[160]\ttrain-mlogloss:0.189192\n",
      "[161]\ttrain-mlogloss:0.188113\n",
      "[162]\ttrain-mlogloss:0.187195\n",
      "[163]\ttrain-mlogloss:0.186357\n",
      "[164]\ttrain-mlogloss:0.185802\n",
      "[165]\ttrain-mlogloss:0.184838\n",
      "[166]\ttrain-mlogloss:0.184030\n",
      "[167]\ttrain-mlogloss:0.183381\n",
      "[168]\ttrain-mlogloss:0.182592\n",
      "[169]\ttrain-mlogloss:0.181920\n",
      "[170]\ttrain-mlogloss:0.181049\n",
      "[171]\ttrain-mlogloss:0.180232\n",
      "[172]\ttrain-mlogloss:0.179611\n",
      "[173]\ttrain-mlogloss:0.178715\n",
      "[174]\ttrain-mlogloss:0.178036\n",
      "[175]\ttrain-mlogloss:0.177342\n",
      "[176]\ttrain-mlogloss:0.176786\n",
      "[177]\ttrain-mlogloss:0.175950\n",
      "[178]\ttrain-mlogloss:0.175102\n",
      "[179]\ttrain-mlogloss:0.174628\n",
      "[180]\ttrain-mlogloss:0.173861\n",
      "[181]\ttrain-mlogloss:0.173384\n",
      "[182]\ttrain-mlogloss:0.172743\n",
      "[183]\ttrain-mlogloss:0.172252\n",
      "[184]\ttrain-mlogloss:0.171729\n",
      "[185]\ttrain-mlogloss:0.171167\n",
      "[186]\ttrain-mlogloss:0.170432\n",
      "[187]\ttrain-mlogloss:0.169863\n",
      "[188]\ttrain-mlogloss:0.169171\n",
      "[189]\ttrain-mlogloss:0.168539\n",
      "[190]\ttrain-mlogloss:0.167930\n",
      "[191]\ttrain-mlogloss:0.166959\n",
      "[192]\ttrain-mlogloss:0.166252\n",
      "[193]\ttrain-mlogloss:0.165403\n",
      "[194]\ttrain-mlogloss:0.164734\n",
      "[195]\ttrain-mlogloss:0.164172\n",
      "[196]\ttrain-mlogloss:0.163597\n",
      "[197]\ttrain-mlogloss:0.162976\n",
      "[198]\ttrain-mlogloss:0.162322\n",
      "[199]\ttrain-mlogloss:0.161731\n",
      "[200]\ttrain-mlogloss:0.160985\n",
      "[201]\ttrain-mlogloss:0.160249\n",
      "[202]\ttrain-mlogloss:0.159809\n",
      "[203]\ttrain-mlogloss:0.159389\n",
      "[204]\ttrain-mlogloss:0.158799\n",
      "[205]\ttrain-mlogloss:0.158197\n",
      "[206]\ttrain-mlogloss:0.157753\n",
      "[207]\ttrain-mlogloss:0.157348\n",
      "[208]\ttrain-mlogloss:0.156857\n",
      "[209]\ttrain-mlogloss:0.156199\n",
      "[210]\ttrain-mlogloss:0.155739\n",
      "[211]\ttrain-mlogloss:0.155185\n",
      "[212]\ttrain-mlogloss:0.154657\n",
      "[213]\ttrain-mlogloss:0.154145\n",
      "[214]\ttrain-mlogloss:0.153520\n",
      "[215]\ttrain-mlogloss:0.153125\n",
      "[216]\ttrain-mlogloss:0.152512\n",
      "[217]\ttrain-mlogloss:0.151977\n",
      "[218]\ttrain-mlogloss:0.151383\n",
      "[219]\ttrain-mlogloss:0.150725\n",
      "[220]\ttrain-mlogloss:0.150248\n",
      "[221]\ttrain-mlogloss:0.149638\n",
      "[222]\ttrain-mlogloss:0.149019\n",
      "[223]\ttrain-mlogloss:0.148290\n",
      "[224]\ttrain-mlogloss:0.147697\n",
      "[225]\ttrain-mlogloss:0.147148\n",
      "[226]\ttrain-mlogloss:0.146611\n",
      "[227]\ttrain-mlogloss:0.146090\n",
      "[228]\ttrain-mlogloss:0.145478\n",
      "[229]\ttrain-mlogloss:0.145005\n",
      "[230]\ttrain-mlogloss:0.144526\n",
      "[231]\ttrain-mlogloss:0.144079\n",
      "[232]\ttrain-mlogloss:0.143618\n",
      "[233]\ttrain-mlogloss:0.143145\n",
      "[234]\ttrain-mlogloss:0.142553\n",
      "[235]\ttrain-mlogloss:0.141963\n",
      "[236]\ttrain-mlogloss:0.141535\n",
      "[237]\ttrain-mlogloss:0.141001\n",
      "[238]\ttrain-mlogloss:0.140570\n",
      "[239]\ttrain-mlogloss:0.140163\n",
      "[240]\ttrain-mlogloss:0.139590\n",
      "[241]\ttrain-mlogloss:0.139047\n",
      "[242]\ttrain-mlogloss:0.138463\n",
      "[243]\ttrain-mlogloss:0.138057\n",
      "[244]\ttrain-mlogloss:0.137606\n",
      "[245]\ttrain-mlogloss:0.137218\n",
      "[246]\ttrain-mlogloss:0.136710\n",
      "[247]\ttrain-mlogloss:0.136205\n",
      "[248]\ttrain-mlogloss:0.135786\n",
      "[249]\ttrain-mlogloss:0.135283\n",
      "[250]\ttrain-mlogloss:0.134888\n",
      "[251]\ttrain-mlogloss:0.134348\n",
      "[252]\ttrain-mlogloss:0.133873\n",
      "[253]\ttrain-mlogloss:0.133409\n",
      "[254]\ttrain-mlogloss:0.133021\n",
      "[255]\ttrain-mlogloss:0.132715\n",
      "[256]\ttrain-mlogloss:0.132303\n",
      "[257]\ttrain-mlogloss:0.131859\n",
      "[258]\ttrain-mlogloss:0.131499\n",
      "[259]\ttrain-mlogloss:0.130992\n",
      "[0]\ttrain-mlogloss:1.968044\n",
      "[1]\ttrain-mlogloss:1.802627\n",
      "[2]\ttrain-mlogloss:1.663718\n",
      "[3]\ttrain-mlogloss:1.546837\n",
      "[4]\ttrain-mlogloss:1.446054\n",
      "[5]\ttrain-mlogloss:1.355878\n",
      "[6]\ttrain-mlogloss:1.276142\n",
      "[7]\ttrain-mlogloss:1.207006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   each:0.130992, avg:0.130992, Time:0:05:03.244352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[8]\ttrain-mlogloss:1.143354\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a230e5209abe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mwatchlist\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mplst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mbst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mplst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwatchlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m     \u001b[1;31m# bst.save_model(path + 'model/model_XGB_CF_' + str(seed) + '.model')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[0mpred_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, early_stopping_rounds, evals_result, verbose_eval)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mbst_eval_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/ubuntu/anaconda3/lib/python3.4/site-packages/xgboost-0.4-py3.4.egg/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m    521\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'invalid training matrix: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m             \u001b[0m_check_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %load './otto_xgb.py'\n",
    "\"\"\"\n",
    "XGBoost + Count feature, Time: 1:37:22\n",
    "XGBoost + Random indexing, Time: 1:56:58\n",
    "The running times on i7 4790k, 32G MEM, GTX660\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "from datetime import datetime\n",
    "\n",
    "from utility import *\n",
    "\n",
    "path = './'\n",
    "file_train = path + 'train.csv'\n",
    "file_test = path + 'test.csv'\n",
    "\n",
    "training = pd.read_csv(file_train, index_col = 0)\n",
    "test = pd.read_csv(file_test, index_col = 0)\n",
    "num_train = training.shape[0]\n",
    "\n",
    "target = training['target']\n",
    "training.drop('target', inplace = True, axis = 1)\n",
    "\n",
    "df_trans = pd.Series(range(9), index = target.unique())\n",
    "y = target.map(df_trans).values\n",
    "yMat = pd.get_dummies(y).values\n",
    "\n",
    "X = np.vstack((training.values, test.values))\n",
    "\n",
    "\n",
    "# Common parameters\n",
    "nIter = 50\n",
    "tc = 15 # max_depth\n",
    "sh = .1 # eta\n",
    "bf = .8 # subsample\n",
    "\n",
    "### XGB1: Count feature\n",
    "nt = 260\n",
    "mb = 5 # min_child_weight\n",
    "cs = 45. / 93 # colsample_bytree\n",
    "\n",
    "X2, ignore = count_feature(X)\n",
    "dtrain , dtest = xgb.DMatrix(X2[:num_train], label = y), xgb.DMatrix(X2[num_train:])\n",
    "\n",
    "predAll_train = np.zeros((num_train, 9))\n",
    "predAll_test = np.zeros((test.shape[0], 9))\n",
    "scores = []\n",
    "\n",
    "t0 = datetime.now()\n",
    "for i in range(nIter):\n",
    "    seed = i + 123\n",
    "    param = {'bst:max_depth':tc, 'bst:eta':sh, 'silent':1, 'objective':'multi:softprob','num_class':9,\n",
    "             'min_child_weight':mb, 'subsample':bf, 'colsample_bytree':cs, 'nthread':4, 'seed':seed,'eval_metric': 'mlogloss'}\n",
    "    watchlist  = [(dtrain,'train')]\n",
    "    plst = param.items()\n",
    "    bst = xgb.train(plst, dtrain, nt,watchlist)\n",
    "    # bst.save_model(path + 'model/model_XGB_CF_' + str(seed) + '.model')\n",
    "    pred_train = bst.predict(dtrain).reshape((num_train, 9))\n",
    "    pred_test = bst.predict(dtest).reshape(predAll_test.shape)\n",
    "    predAll_train += pred_train\n",
    "    predAll_test += pred_test\n",
    "    sc1 = log_loss(yMat, pred_train)\n",
    "    sc2 = log_loss(yMat, predAll_train / (i + 1))\n",
    "    print (i, \"  each:%f, avg:%f, Time:%s\" % (sc1, sc2, datetime.now() - t0))\n",
    "\n",
    "# 49   each:0.131026, avg:0.130512, Time:1:37:21.187174\n",
    "pred_XGB_CF = predAll_test / nIter\n",
    "np.save(path + 'pred_XGB_CF.npy', pred_XGB_CF)\n",
    "\n",
    "### XGB2: Random Indexing\n",
    "X1 = X / X.mean(0)\n",
    "\n",
    "m = 140\n",
    "k = 2\n",
    "nt = 220\n",
    "mb = 10 # min_child_weight\n",
    "cs = 50. / 93 # colsample_bytree\n",
    "\n",
    "predAll_train = np.zeros((num_train, 9))\n",
    "predAll_test = np.zeros((test.shape[0], 9))\n",
    "t0 = datetime.now()\n",
    "for i in range(nIter):\n",
    "    seed = i + 123210\n",
    "    X3 = RI(X1, m, k, normalize = False, seed = seed)\n",
    "    dtrain = xgb.DMatrix(X3[:num_train], label = y)\n",
    "    dtest = xgb.DMatrix(X3[num_train:])\n",
    "    watchlist  = [(dtrain,'train')]\n",
    "    param = {'bst:max_depth':tc, 'bst:eta':sh, 'silent':1, 'objective':'multi:softprob',\n",
    "             'num_class':9, 'min_child_weight':mb, 'subsample':bf,\n",
    "             'colsample_bytree':cs, 'nthread':4, 'seed':seed}\n",
    "    plst = param.items()\n",
    "    bst = xgb.train(plst, dtrain, nt,watchlist)\n",
    "    # bst.save_model(path + 'model/model_XGB_RI_' + str(seed) + '.model')\n",
    "    pred_train = bst.predict(dtrain).reshape((num_train, 9))\n",
    "    pred_test = bst.predict(dtest).reshape(predAll_test.shape)\n",
    "    predAll_train += pred_train\n",
    "    predAll_test += pred_test\n",
    "    sc1 = log_loss(yMat, pred_train)\n",
    "    sc2 = log_loss(yMat, predAll_train / (i + 1))\n",
    "    print (i, \"  each:%f, avg:%f, Time:%s\" % (sc1, sc2, datetime.now() - t0))\n",
    "\n",
    "# 49   each:0.085345, avg:0.084942, Time:1:56:57.580157\n",
    "pred_XGB_RI = predAll_test / nIter\n",
    "np.save(path + 'pred_XGB_RI.npy', pred_XGB_RI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
